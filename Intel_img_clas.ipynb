{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intel_img_clas.ipynb",
      "provenance": [],
      "mount_file_id": "1MMs7NXUqOVBoe4571_KA4MxNLzVhFAWq",
      "authorship_tag": "ABX9TyNuJO2pjssx/N2t+1UDLKhD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahulraj31/Intel-Image-Classification/blob/main/Intel_img_clas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz2J4xWbMiQQ"
      },
      "source": [
        "import PIL.Image as Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,losses\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArCaJhQ6Q2EY"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "local_zip = '/content/drive/MyDrive/Colab Notebooks/Intel_Img_Class.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iG-OVuJjRJOQ",
        "outputId": "0e2e1ed9-dceb-4900-e5f2-06f10feb30d4"
      },
      "source": [
        "from pathlib import Path \n",
        "# Define path to the data directory\n",
        "#dir_alldata = \n",
        "\n",
        "# Path to train directory \n",
        "test_data_dir = Path('/content/seg_pred/seg_pred')\n",
        "\n",
        "# Path to validation directory\n",
        "val_data_dir = Path(\"/content/seg_test/seg_test\")\n",
        "\n",
        "# Path to test directory\n",
        "train_data_dir = Path(\"/content/seg_train/seg_train\")\n",
        "\n",
        "# Get the path to the normal and pneumonia sub-directories\n",
        "\"\"\"normal_cases_train = train_data_dir / 'NORMAL'\n",
        "pneumonia_cases_train = train_data_dir / 'PNEUMONIA'\"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"normal_cases_train = train_data_dir / 'NORMAL'\\npneumonia_cases_train = train_data_dir / 'PNEUMONIA'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT53Gjw2SDzf"
      },
      "source": [
        "train_images_dict = {\n",
        "    'building': list(train_data_dir.glob('buildings/*')) ,   \n",
        "    'forest': list(train_data_dir.glob('forest/*')),\n",
        "    'glacier': list(train_data_dir.glob('glacier/*')),\n",
        "    'mountain': list(train_data_dir .glob('mountain/*')),\n",
        "    'sea': list(train_data_dir.glob('sea/*')),\n",
        "    'street': list(train_data_dir.glob('street/*')), \n",
        "}\n",
        "\n",
        "\n",
        "val_images_dict = {\n",
        "     'building': list(val_data_dir.glob('buildings/*')) ,   \n",
        "    'forest': list(val_data_dir.glob('forest/*')),\n",
        "    'glacier': list(val_data_dir.glob('glacier/*')),\n",
        "    'mountain': list(val_data_dir .glob('mountain/*')),\n",
        "    'sea': list(val_data_dir.glob('sea/*')),\n",
        "    'street': list(val_data_dir.glob('street/*')), \n",
        "}\n",
        "\n",
        "\n",
        "labels_dict = {\n",
        "     'building': \"building\", \n",
        "    'forest': \"forest\",\n",
        "    'glacier': \"glacier\",\n",
        "    'mountain': \"mountain\",\n",
        "    'sea': \"sea\",\n",
        "    'street': \"street\", \n",
        "}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saZV_0zATvW-",
        "outputId": "f23e9942-0dca-41a3-939f-1d5a7e661d4b"
      },
      "source": [
        "img= cv2.imread(str(train_images_dict['building'][0]))\n",
        "img.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO4C5nZbT1Pm",
        "outputId": "189c6f28-24d9-452c-cef3-7ca790f50eed"
      },
      "source": [
        "Xtrain, ytrain = [], []\n",
        "for name,images in train_images_dict.items():#returns key , path for each record\n",
        "    for image in images:\n",
        "        img=str(image)\n",
        "    \n",
        "        Xtrain.append(img)\n",
        "        ytrain.append(labels_dict[name])\n",
        "\n",
        "\n",
        "Fseries = pd.Series(Xtrain, name=\"filepaths\",dtype=str)\n",
        "Lseries = pd.Series(ytrain, name=\"labels\",dtype=str)\n",
        "train_data = pd.concat([Fseries,Lseries], axis=1)\n",
        "train_df = pd.DataFrame(train_data)\n",
        "\n",
        "print(train_df[\"labels\"].value_counts())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mountain    2512\n",
            "glacier     2404\n",
            "street      2382\n",
            "sea         2274\n",
            "forest      2271\n",
            "building    2191\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frBHTD1yUCr9",
        "outputId": "dd236c6c-e1b0-48b9-950b-f0fd3fc9fa09"
      },
      "source": [
        "Xval, yval = [], []\n",
        "for name,images in val_images_dict.items():#returns key , path for each record\n",
        "    for image in images:\n",
        "        img=str(image)\n",
        "    \n",
        "        Xval.append(img)\n",
        "        yval.append(labels_dict[name])\n",
        "\n",
        "\n",
        "Fseries = pd.Series(Xval, name=\"filepaths\",dtype=str)\n",
        "Lseries = pd.Series(yval, name=\"labels\",dtype=str)\n",
        "val_data = pd.concat([Fseries,Lseries], axis=1)\n",
        "val_df = pd.DataFrame(val_data)\n",
        "\n",
        "val_df[\"labels\"].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "glacier     553\n",
              "mountain    525\n",
              "sea         510\n",
              "street      501\n",
              "forest      474\n",
              "building    437\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBQ6rGi4ULj9",
        "outputId": "25a21348-254e-4e8e-d2ad-4c713ff7fa9e"
      },
      "source": [
        "#Generate batches of tensor image data with real-time data augmentation.\n",
        "\n",
        "image_gen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   \n",
        "                                   \n",
        "                                   rotation_range = 40,\n",
        "                                  shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   fill_mode = 'nearest'\n",
        "    \n",
        ")\n",
        "\n",
        "train = image_gen.flow_from_dataframe(dataframe= train_df,x_col=\"filepaths\",y_col=\"labels\",\n",
        "                                      target_size=(150,150),\n",
        "                                     \n",
        "                                      class_mode=\"categorical\", #used for Sequential Model\n",
        "                                      batch_size=32,\n",
        "                                      shuffle=False            #do not shuffle data\n",
        "                                     )\n",
        "\n",
        "val = image_gen.flow_from_dataframe(dataframe= val_df,x_col=\"filepaths\", y_col=\"labels\",\n",
        "                                    target_size=(150,150),\n",
        "                                   \n",
        "                                    class_mode=\"categorical\",\n",
        "                                    batch_size=32,\n",
        "                                    shuffle=False\n",
        "                                   )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14034 validated image filenames belonging to 6 classes.\n",
            "Found 3000 validated image filenames belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3gTsbeBUnGO",
        "outputId": "012b7d6b-ae28-4429-a384-8705a39f7ac3"
      },
      "source": [
        "classes=list(train.class_indices.keys())\n",
        "print (classes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['building', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_pDGXSKUw5m"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "cnn_base = VGG16(include_top = False,\n",
        "                 weights = 'imagenet',\n",
        "                 input_shape = (150, 150, 3),\n",
        "                 classes = 6,\n",
        "                 classifier_activation = 'softmax')\n",
        "\n",
        "cnn_base.trainable = False"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlBvhODrU0mF"
      },
      "source": [
        "pretrainedCNN_model = Sequential([\n",
        "                                     cnn_base,\n",
        "                                  layers.Flatten(),\n",
        "                                  layers.Dense(640, activation = 'relu'),\n",
        "                                  layers.Dropout(0.5),\n",
        "                                  layers.Dense(128, activation = 'relu'),\n",
        "                                  layers.Dropout(0.5),\n",
        "                                  layers.Dense(6, activation = 'softmax')  ,  \n",
        "])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pge3AUkU6eO"
      },
      "source": [
        "\n",
        "pretrainedCNN_model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "                            optimizer = keras.optimizers.Adam(0.0001),\n",
        "                            metrics = ['acc'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTP8cs0AVUGd",
        "outputId": "fcc69a13-02e6-4fee-c117-1c3e083d1e59"
      },
      "source": [
        "pretrainedCNN_model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 640)               5243520   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               82048     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 20,041,030\n",
            "Trainable params: 5,326,342\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmLYq455VVrN",
        "outputId": "64b74ca2-2b59-476b-bc6c-b850c276ac40"
      },
      "source": [
        "History = pretrainedCNN_model.fit(train, validation_data= val, epochs=10,verbose=1,\n",
        "                                  steps_per_epoch=1000//32,\n",
        "                                  validation_steps=100//32)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "439/439 [==============================] - 95s 215ms/step - loss: 1.2804 - acc: 0.4900 - val_loss: 0.7676 - val_acc: 0.7223\n",
            "Epoch 2/10\n",
            "439/439 [==============================] - 90s 205ms/step - loss: 0.8514 - acc: 0.6652 - val_loss: 0.6239 - val_acc: 0.7753\n",
            "Epoch 3/10\n",
            "439/439 [==============================] - 90s 205ms/step - loss: 0.7574 - acc: 0.7064 - val_loss: 0.5890 - val_acc: 0.7780\n",
            "Epoch 4/10\n",
            "439/439 [==============================] - 90s 205ms/step - loss: 0.6628 - acc: 0.7520 - val_loss: 0.5867 - val_acc: 0.7737\n",
            "Epoch 5/10\n",
            "439/439 [==============================] - 89s 204ms/step - loss: 0.6538 - acc: 0.7583 - val_loss: 0.5256 - val_acc: 0.8047\n",
            "Epoch 6/10\n",
            "439/439 [==============================] - 89s 204ms/step - loss: 0.6263 - acc: 0.7671 - val_loss: 0.5162 - val_acc: 0.8097\n",
            "Epoch 7/10\n",
            "439/439 [==============================] - 89s 204ms/step - loss: 0.5952 - acc: 0.7806 - val_loss: 0.4870 - val_acc: 0.8203\n",
            "Epoch 8/10\n",
            "439/439 [==============================] - 89s 204ms/step - loss: 0.5824 - acc: 0.7874 - val_loss: 0.5573 - val_acc: 0.7760\n",
            "Epoch 9/10\n",
            "439/439 [==============================] - 89s 204ms/step - loss: 0.5753 - acc: 0.7889 - val_loss: 0.4869 - val_acc: 0.8097\n",
            "Epoch 10/10\n",
            "439/439 [==============================] - 89s 203ms/step - loss: 0.5540 - acc: 0.7949 - val_loss: 0.4880 - val_acc: 0.8173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBj6m40XVcaW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}